# -*- coding: utf-8 -*-
"""MVP_SPRINT1_JGAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/jgamiranda/676c94d56206ac72a9ce97a6d9dfbccd/mvp_jgam_data.ipynb

O dataset escolhido para o MVP foi retirado do repositório UCI, consistindo em informações provenientes da pesquisa censitária de 1994 nos Estados Unidos. Trata-se de um dataset com dados estruturados.

<h1> 1. DEFINIÇÃO DO PROBLEMA <h1>

*1.1 Descrição do Problema | Tipo de Aprendizado*
<br> O dataset possui como *target* uma variável categórica binária, determinando se o indíviduo possui **renda anual acima de USD 50 mil**, na data-base de 1994. A partir de variáveis quantitativas e qualitativas, é possível empregar um modelo de classificação, separando o dataset em amostras de "treino" e "teste" para a predição da variável target binária. </br>
<br>

*1.2 Premissas e Hipóteses*
<br> As minhas premissas iniciais baseiam-se na assunção de que haja um efeito positivo (como nesse caso, a variável **renda anual acima de USD 50 mil** é binária, não podemos falar que haja correlação) entre as seguintes variáveis, e a variável target **renda anual acima de USD 50 mil**: </br>

1.   **Idade**: minha premissa é de que pessoas com **idades maiores** possuam mais experiência de trabalho e, portanto, de forma geral ocupam cargos mais sêniores, que possuem remuneração mais elevada. Mas essa presunção está sujeita a diversas críticas e desconstruções em virtude de variáveis categóricas, como função de trabalho e tipo de empregador. 
2.   **Anos Estudo**: minha premissa é de que pessoas com mais anos de estudo, de forma geral, sejam mais especializadas e, portanto, haja maior demanda por seu tipo de trabalho.
3.   **Horas Semanais Trabalhadas:** dado que a amostra é retirada do censo de 1994 dos EUA, como o regime trabalhista permite a contratação por hora de trabalho, a rigor, quanto mais horas trabalhadas, maior a renda. No entanto, há de se levar em conta que, nestes casos, a renda é proveniente do produto entre **# de horas trabalhadas** x **salário por hora**


*1.3 Definição dos Atributos do Dataset*
<br> O dataset possui 14 atributos conforme elencado abaixo: </br>

1.   **age:** idade | variável numérica discreta
2.   **workclass:** tipo de relação trabalhista/empregador | variável categórica nominal
3.   **fnlwgt:** peso ponderado da observação na amostra baseado na representatividade na população | variável contínua numérica
4.   **education:** nível de formação educacional | variável categórica ordinal
5.   **education-num**: número de anos de estudo | variável discreta numérica
6.   **marital-status**: estado civil | variável categórica nominal
7.   **occupation**: profissão | variável categórica nominal
8.   **relationship**: ocupação familiar | variável categórica nominal
9.   **race**: etnia | variável categórica nominal
10.  **sex**: gênero | variável categórica nominal
11.  **capital-gain**: valor auferido em ganhos de capital ao longo do ano | variável numérica contínua
12.  **capital-loss**: valor negativo de ganhos de capital ao longo do ano | variável numérica contínua
13.  **hours-per-week**: número de horas trabalhadas por semana | variável numérica contínua 
14. **native-country**: país de nascimento do indivíduo | variável categórica nominal 


*1.4 Restrições ou Condições para selecionar os dados*
<br> Por se tratar de uma base de dados provenientes de um censo populacional, há alguns disclaimers a serem feitos acerca dos dados colhidos:
 </br>

*   **Viés da Amostra**: Por mais que a variável **"fnlwgt"** busque retirar vieses da amostra colhida pelo censo, pode haver falhas em sua aplicação.
*   **Auto-declaração**: Os dados censitários são recolhidos a partir de auto-declaração, o que não necessariamente se traduzirá em declarações sem vieses ou distorção
*   **Restrição de respostas**: A opção para resposta em atributos cujo conteúdo é de natureza nominal categórica, pode impor um universo limitado declaratório
*   **Correlação entre atributos**: Pode existir uma correlação significativa entre dois atributos ou mais. Por exemplo, a quantidade de anos em nível de formação educacional, tende a ser maior para indivíduos com maior idade

Há, por fim, uma questão na aplicação deste dataset para treinamento de um modelo de predição: a base é referente a apenas um ano, de 1994, sendo um ponto discreto na coleta de dados censitários. Portanto, pode haver vieses específicos do ano de 1994 que irão influenciar a qualidade de predição. Destes, entendo que as duas variáveis relacionadas a ganhos de capital (**"capital-gain"** e **"capital-loss"**) são exemplos emblemáticos, visto que, ganhos de capital, como via de regra, não advém de "streams" relativamente estáveis de renda (como, por exemplo, é o caso de **salários** e **dividendos**), mas de eventos específicos de liquidez (como é o caso de **venda de bens móveis e imóveis**), que possuem natureza estocástica.
"""

# importação dos pacote pandas
import pandas as pd

# link para importar o arquivo de destino
link = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"

#labels para modificar o nome de cada coluna a fim de deixá-las auto-explicativas
labels = ["idade", "tipo_emprego", "ponderacao", "formacao", "anos_estudo", "estado_civil", "profissao", "ocupacao_familiar", "etnia", "genero", "capganho", "capganho_neg", "horas_semanais_trab", "origem", "renda_anual_acima_de_50k"]

# importar dataset
base_censo_94 = pd.read_csv(link, header=12, names=labels, index_col = False)
base_censo_94.head(5)

"""<h1> 2. ANÁLISE DE DADOS <h1>

Após checar que as colunas se encontram com cabeçalhos condizentes após a importação do arquivo .csv e aplicação dos labels nos atributos, vou checar se há valores nulos nas colunas, já tendo visto acima que valores não respondidos parecem estar assinalados por "?".
"""

# checar informações básicas sobre as colunas
print(base_censo_94.info())

"""Como ao declarar o método ".head()", fica claro que há inputs com "?" para dados não inputados, importo o pacote **numpy** para substituir todos e quaisquer inputs de **"?"** no dataset por **"NaN"** e resumir quantas entradas faltantes há em cada coluna do dataset."""

# importar o pacote numpy
import numpy as np

# substituir valores "?" por NaN e checar quais colunas possuem variáveis não-preenchidas
base_censo_94.replace(" ?", np.nan, inplace=True)
print(base_censo_94.isna().sum())

# checar se substituição foi realizada de forma correta
base_censo_94.head(5)

"""Com o objetivo de tornar a visualização e manipulação de dados mais simples na sintaxe, substituo os valores da variável target **renda anual acima de USD 50 mil** pelos seguintes:
a) maior do que USD 50 mil (> 50k): 1
b) menor ou igual a USD 50 mil (<= 50k): 0

Como existem apenas duas variáveis, vou utilizar o método **replace**.
"""

base_censo_94.groupby("renda_anual_acima_de_50k").size()

# substituindo os valores da coluna "renda_anual_acima_de_50k" para assumirem o caráter categórico binário de "sim" e "não" afim de facilitar
# o uso no código e na visualização para tratar a base
base_censo_94["renda_anual_acima_de_50k"] = base_censo_94["renda_anual_acima_de_50k"].replace({" >50K": 1, " <=50K": 0})

# checar se a mudança foi corretamente aplicada
base_censo_94.head()

# checar métricas estatísticas das variáveis numéricas
base_censo_94.describe()

"""Como podemos observar, as métricas estatísticas do atributo **ponderacao** não geram muito significado. Alguns dos atributos, como **capganho** e **capganho_neg** (pela distribuição dos quartis) e **horas_semanais_trab** (pelos valores **máximo** e **mínimo**), despertam dúvidas sobre a distribuição de dados e potencial existência de *outliers*. Afim de analisar as distribuições visualmente, vou criar um histograma para avaliar o perfil das distribuições de variáveis numéricas."""

import matplotlib.pyplot as plt
base_censo_94.hist(figsize=(10,10))
plt.show()

base_censo_94.plot(kind="box", subplots = True, layout = (3,3), sharex = False, sharey = False, figsize = (15,10))
plt.show()

"""A partir dos histogramas e dos gráficos de dispersão acima, fica evidente o caráter assimétrico dos seguintes atributos:


1.   idade
2.   capganho
3.   capganho_neg

Vale destacar ainda, que atributos do *dataset* como **anos_de_estudo** e **horas_semanais_trab** possuem *outliers* conforme exposto pelo boxplot.

Dada a característica pontual dos dados de ganho de capital representados por estes atributos, e a sua distribuição, é necessário avaliar a sua adequação/inclusão no modelo de *machine learning* para predição.

Com o intuito de olhar o *big picture* dos atributos, suas respectivas distribuições e eventuais relações entre si, vou utilizar o método Pairplot do pacote Seaborn, que reúne todos os tipos mencionados de visualização.
"""

# importando o pacote seaborn
import seaborn as sns

# utilizando o método pairplot no pacote seaborn
sns.pairplot(data=base_censo_94, hue="renda_anual_acima_de_50k")

"""A análise dos gráficos de dispersão, sugere que, quanto maior os **anos_estudo** e maior a **idade**, maior é a população com renda acima de **US$ 50k**. A análise corrobora com duas das hipóteses iniciais. Vou utilizar o heatmap para explorar a correlação entre as todas as variáveis, mas especialmente para as variáveis **anos_estudo** e **idade** cuja própria natureza de relação pode incorrer em alta correlação. 


"""

sns.heatmap(base_censo_94.corr(), annot=True, cmap="RdBu", vmin=-1, vmax=1)

"""Conforme hipótese inicial, os atributos **anos_estudo** e **idade** possuem a maior correlação entre atributos do dataset, de **0.23**. Os atributos **idade** e **horas_semanais_trab** possuem o segunda maior índice de correlação entre os atributos, de **0.15**. A rigor, não é possível retirar conclusões específicas sobre essas correlações.
Em tempo, a correlação da variável *target* com os demais atributos não deve ser utilizada para se chegar a conclusões definitivas.
De forma geral, não existem correlações relevantes entre os atributos do dataset.

<h1> 3. PRÉ-PROCESSAMENTO DE DADOS <h1>

Após realizar a análise dos dados, é necessário passar pela etapa de pré-processamento de dados.
Como início de pré-tratamento, eliminarei os valores missing já apurados.
"""

# listagem de ocorrências de valores missing
base_censo_94.isnull().sum()

"""Por razões qualitativas e de distribuição, retirarei do dataset os atributos de **ponderacao**, **ganhocap** e **ganhocap_neg**."""

# exclusão de linhas com entradas de valores missing
censo94_tratado = base_censo_94.dropna(how="any")
censo94_tratado.head(5)

# checagem para apurar se as linhas com valores missing foram corretamente excluídas do dataset
censo94_tratado.isna().sum()

"""Com o objetivo de normalizar as distribuições dos atributos **idade**, **anos_estudo** e **horas_semanais_trab**, vou utilizar o **MinMaxScaler** do pacote scikit-learn."""

# importando o MinMaxScaler
from sklearn.preprocessing import MinMaxScaler

normalizacao = MinMaxScaler()

# adicionando os atributos para normalização
normalizacao.fit(censo94_tratado[["idade", "anos_estudo", "horas_semanais_trab"]])

# normalizando os atributos
censo94_tratado[["idade", "anos_estudo", "horas_semanais_trab"]] = normalizacao.transform(censo94_tratado[["idade", "anos_estudo", "horas_semanais_trab"]])

# verificando output dos atributos normalizados
censo94_tratado[["idade", "anos_estudo", "horas_semanais_trab"]]

